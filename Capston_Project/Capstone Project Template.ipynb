{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US Immigration and Temperature\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This capstone project is to give a chance to combine what I've learned throughout this programme. The project is to create the ETL pipeline to create a database for useful insights and analysis. For example, is there any immigration age or nationality distribtuion? or do immigrates prefer warmer places?\n",
    "\n",
    "#### The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd, re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 212.4MB 133kB/s eta 0:00:01 2% |▉                               | 5.4MB 28.4MB/s eta 0:00:08    5% |█▋                              | 10.7MB 28.1MB/s eta 0:00:08    5% |█▉                              | 12.0MB 27.6MB/s eta 0:00:08    8% |██▋                             | 17.1MB 27.1MB/s eta 0:00:08    10% |███▍                            | 22.3MB 27.3MB/s eta 0:00:07    11% |███▌                            | 23.6MB 27.2MB/s eta 0:00:07    11% |███▊                            | 24.9MB 26.6MB/s eta 0:00:08    12% |████                            | 26.1MB 27.0MB/s eta 0:00:07    13% |████▎                           | 28.6MB 23.7MB/s eta 0:00:08    14% |████▌                           | 29.9MB 27.2MB/s eta 0:00:07    15% |█████                           | 33.7MB 26.0MB/s eta 0:00:07    16% |█████▎                          | 35.0MB 27.0MB/s eta 0:00:07    17% |█████▋                          | 37.4MB 25.3MB/s eta 0:00:07    18% |█████▉                          | 38.7MB 25.7MB/s eta 0:00:07    18% |██████                          | 39.9MB 26.3MB/s eta 0:00:07    19% |██████▏                         | 41.1MB 24.1MB/s eta 0:00:08    21% |██████▊                         | 44.7MB 24.1MB/s eta 0:00:07    21% |███████                         | 45.9MB 25.4MB/s eta 0:00:07    22% |███████                         | 47.1MB 25.8MB/s eta 0:00:07    23% |███████▍                        | 49.4MB 24.5MB/s eta 0:00:07    24% |████████                        | 52.8MB 24.4MB/s eta 0:00:07    25% |████████▎                       | 55.0MB 23.2MB/s eta 0:00:07    26% |████████▌                       | 56.1MB 24.0MB/s eta 0:00:07    26% |████████▋                       | 57.2MB 25.8MB/s eta 0:00:07    27% |████████▉                       | 58.4MB 23.7MB/s eta 0:00:07    30% |█████████▉                      | 64.9MB 22.4MB/s eta 0:00:07    31% |██████████                      | 65.9MB 21.9MB/s eta 0:00:07    31% |██████████                      | 67.0MB 25.5MB/s eta 0:00:06    32% |██████████▍                     | 69.1MB 24.1MB/s eta 0:00:06    33% |██████████▊                     | 71.1MB 21.2MB/s eta 0:00:07    34% |██████████▉                     | 72.2MB 22.1MB/s eta 0:00:07    34% |███████████▏                    | 74.1MB 21.2MB/s eta 0:00:07    35% |███████████▍                    | 75.3MB 24.8MB/s eta 0:00:06    36% |███████████▋                    | 77.2MB 22.4MB/s eta 0:00:07    36% |███████████▊                    | 78.1MB 23.1MB/s eta 0:00:06    38% |████████████▏                   | 80.8MB 19.8MB/s eta 0:00:07    38% |████████████▎                   | 81.6MB 14.9MB/s eta 0:00:09    38% |████████████▍                   | 82.1MB 16.6MB/s eta 0:00:08    41% |█████████████▏                  | 87.2MB 26.2MB/s eta 0:00:05    41% |█████████████▎                  | 88.4MB 22.9MB/s eta 0:00:06    42% |█████████████▌                  | 90.0MB 11.1MB/s eta 0:00:12    42% |█████████████▊                  | 91.0MB 24.9MB/s eta 0:00:05    43% |█████████████▉                  | 92.0MB 20.0MB/s eta 0:00:07    44% |██████████████▏                 | 94.1MB 22.8MB/s eta 0:00:06    45% |██████████████▋                 | 97.2MB 23.5MB/s eta 0:00:05    46% |██████████████▉                 | 98.2MB 20.4MB/s eta 0:00:06    47% |███████████████▎                | 101.2MB 24.8MB/s eta 0:00:05    48% |███████████████▍                | 102.2MB 20.4MB/s eta 0:00:06    48% |███████████████▌                | 103.1MB 23.2MB/s eta 0:00:05    50% |████████████████                | 106.3MB 19.9MB/s eta 0:00:06    50% |████████████████▏               | 107.3MB 20.1MB/s eta 0:00:06    50% |████████████████▎               | 108.2MB 13.5MB/s eta 0:00:08    51% |████████████████▋               | 110.3MB 25.0MB/s eta 0:00:05    52% |████████████████▊               | 111.3MB 18.8MB/s eta 0:00:06    52% |█████████████████               | 112.5MB 30.2MB/s eta 0:00:04    53% |█████████████████               | 112.9MB 3.9MB/s eta 0:00:26    53% |█████████████████▎              | 114.6MB 20.5MB/s eta 0:00:05    55% |█████████████████▉              | 118.6MB 26.4MB/s eta 0:00:04    56% |██████████████████▏             | 120.7MB 26.5MB/s eta 0:00:04    57% |██████████████████▍             | 122.0MB 24.6MB/s eta 0:00:04    57% |██████████████████▌             | 123.1MB 18.5MB/s eta 0:00:05    58% |██████████████████▊             | 124.4MB 28.0MB/s eta 0:00:04    59% |███████████████████             | 125.8MB 29.2MB/s eta 0:00:03    60% |███████████████████▎            | 128.2MB 25.8MB/s eta 0:00:04    60% |███████████████████▌            | 129.5MB 33.6MB/s eta 0:00:03    61% |███████████████████▉            | 131.6MB 19.1MB/s eta 0:00:05    62% |████████████████████▏           | 133.7MB 26.0MB/s eta 0:00:04    63% |████████████████████▎           | 134.9MB 20.2MB/s eta 0:00:04    64% |████████████████████▋           | 137.1MB 26.6MB/s eta 0:00:03    65% |████████████████████▉           | 138.5MB 24.7MB/s eta 0:00:03    65% |█████████████████████           | 139.8MB 27.5MB/s eta 0:00:03    66% |█████████████████████▎          | 141.2MB 27.9MB/s eta 0:00:03    67% |█████████████████████▋          | 143.7MB 41.1MB/s eta 0:00:02    68% |██████████████████████          | 145.6MB 20.9MB/s eta 0:00:04    69% |██████████████████████▏         | 146.9MB 36.6MB/s eta 0:00:02    69% |██████████████████████▎         | 148.0MB 19.3MB/s eta 0:00:04    70% |██████████████████████▌         | 149.3MB 31.8MB/s eta 0:00:02    71% |██████████████████████▉         | 151.7MB 26.0MB/s eta 0:00:03    72% |███████████████████████         | 153.0MB 31.7MB/s eta 0:00:02    72% |███████████████████████▏        | 154.0MB 19.4MB/s eta 0:00:04    72% |███████████████████████▎        | 154.8MB 17.0MB/s eta 0:00:04    73% |███████████████████████▌        | 156.1MB 28.0MB/s eta 0:00:03    74% |███████████████████████▉        | 158.1MB 24.5MB/s eta 0:00:03    75% |████████████████████████▏       | 160.3MB 22.0MB/s eta 0:00:03    76% |████████████████████████▍       | 161.7MB 25.6MB/s eta 0:00:02    76% |████████████████████████▌       | 162.9MB 19.1MB/s eta 0:00:03    76% |████████████████████████▋       | 163.6MB 12.7MB/s eta 0:00:04    77% |████████████████████████▊       | 164.3MB 20.5MB/s eta 0:00:03    77% |█████████████████████████       | 165.6MB 25.0MB/s eta 0:00:02    78% |█████████████████████████▏      | 166.8MB 30.2MB/s eta 0:00:02    79% |█████████████████████████▎      | 167.9MB 21.8MB/s eta 0:00:03    79% |█████████████████████████▌      | 169.2MB 18.1MB/s eta 0:00:03    80% |█████████████████████████▊      | 170.6MB 36.3MB/s eta 0:00:02    81% |██████████████████████████      | 172.6MB 13.8MB/s eta 0:00:03    81% |██████████████████████████▏     | 173.7MB 22.2MB/s eta 0:00:02    82% |██████████████████████████▍     | 174.9MB 22.1MB/s eta 0:00:02    82% |██████████████████████████▋     | 176.3MB 26.8MB/s eta 0:00:02    83% |██████████████████████████▉     | 177.8MB 29.3MB/s eta 0:00:02    84% |███████████████████████████     | 179.1MB 22.3MB/s eta 0:00:02    84% |███████████████████████████     | 179.9MB 20.1MB/s eta 0:00:02    85% |███████████████████████████▍    | 182.0MB 32.2MB/s eta 0:00:01    86% |███████████████████████████▋    | 183.1MB 13.8MB/s eta 0:00:03    86% |███████████████████████████▊    | 184.2MB 30.1MB/s eta 0:00:01    87% |████████████████████████████    | 186.3MB 31.1MB/s eta 0:00:01    88% |████████████████████████████▏   | 187.2MB 13.5MB/s eta 0:00:02    88% |████████████████████████████▎   | 187.9MB 14.5MB/s eta 0:00:02    88% |████████████████████████████▌   | 188.9MB 16.3MB/s eta 0:00:02    89% |████████████████████████████▋   | 190.1MB 20.4MB/s eta 0:00:02    90% |████████████████████████████▉   | 191.5MB 36.1MB/s eta 0:00:01    90% |█████████████████████████████   | 192.7MB 21.7MB/s eta 0:00:01    91% |█████████████████████████████▏  | 193.8MB 22.0MB/s eta 0:00:01    91% |█████████████████████████████▍  | 195.0MB 22.5MB/s eta 0:00:01    92% |█████████████████████████████▋  | 196.4MB 31.2MB/s eta 0:00:01    93% |█████████████████████████████▉  | 197.8MB 38.5MB/s eta 0:00:01    93% |██████████████████████████████  | 199.1MB 21.4MB/s eta 0:00:01    94% |██████████████████████████████▏ | 200.4MB 27.2MB/s eta 0:00:01    95% |██████████████████████████████▋ | 203.1MB 23.5MB/s eta 0:00:01    96% |███████████████████████████████ | 205.8MB 19.4MB/s eta 0:00:01    97% |███████████████████████████████▎| 207.9MB 22.6MB/s eta 0:00:01    98% |███████████████████████████████▌| 209.3MB 20.0MB/s eta 0:00:01    99% |████████████████████████████████| 212.2MB 43.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.9 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 9.7MB/s eta 0:00:01    61% |███████████████████▉            | 122kB 13.9MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Found existing installation: py4j 0.10.7\n",
      "    Uninstalling py4j-0.10.7:\n",
      "      Successfully uninstalled py4j-0.10.7\n",
      "  Found existing installation: pyspark 2.4.3\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark --upgrade\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, count, col, year, month, avg, isnull, round\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark =spark.read.load('./sas_data')\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "3 different sources will be used to create fact and dimension tables. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "- I94 Immigration Data: comes from the U.S. National Tourism and Trade Office and contains various statistics on international visitor arrival in USA and comes from the US National Tourism and Trade Office. ([link](https://www.trade.gov/national-travel-and-tourism-office)).\n",
    "- World Temperature Data: This dataset came from Kaggle and includes the information about the average weather temperatures. ([link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)).\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft and includes the information about the demographics of US cities such as average age, gender distribution. ([link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the I94 immigration data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "imm_df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "\n",
       "  airline        admnum fltno visatype  \n",
       "0     NaN  1.897628e+09   NaN       B2  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the temperature data here\n",
    "temp_fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temp_df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(temp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dt='1743-11-01', AverageTemperature='6.068', AverageTemperatureUncertainty='1.7369999999999999', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the demographic data here\n",
    "demog_fname = 'us-cities-demographics.csv'\n",
    "demog_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(demog_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 i94 Immigration data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247161e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247080e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247849e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MI   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "7   20.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "8   21.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "9   22.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "5  20555.0   ...         NaN        M   1959.0  09302016    NaN    NaN   \n",
       "6  20558.0   ...         NaN        M   1953.0  09302016    NaN    NaN   \n",
       "7  20558.0   ...         NaN        M   1959.0  09302016    NaN    NaN   \n",
       "8  20553.0   ...         NaN        M   1970.0  09302016    NaN    NaN   \n",
       "9  20562.0   ...         NaN        M   1968.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "5      AZ  9.247104e+10  00602       B1  \n",
       "6      AZ  9.247140e+10  00602       B2  \n",
       "7      AZ  9.247161e+10  00602       B2  \n",
       "8      AZ  9.247080e+10  00602       B2  \n",
       "9      AZ  9.247849e+10  00608       B1  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3096303</th>\n",
       "      <td>4471817.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>PHU</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429629e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096304</th>\n",
       "      <td>4471819.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>PHU</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429643e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096305</th>\n",
       "      <td>5011591.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SKA</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10182016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.397554e+10</td>\n",
       "      <td>00490</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096306</th>\n",
       "      <td>4249464.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SUM</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10212016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.426909e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096307</th>\n",
       "      <td>5416391.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SUM</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MN</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>10262016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.471480e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096308</th>\n",
       "      <td>625229.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SYS</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>05082016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.893456e+10</td>\n",
       "      <td>00066</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096309</th>\n",
       "      <td>1972204.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SYS</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>09102016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.030054e+10</td>\n",
       "      <td>00066</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096310</th>\n",
       "      <td>4249448.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>TEC</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>09202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.141672e+10</td>\n",
       "      <td>00651</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096311</th>\n",
       "      <td>5658953.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.488710e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096312</th>\n",
       "      <td>3106671.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>NOG</td>\n",
       "      <td>20561.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>07102016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.605687e+10</td>\n",
       "      <td>00866</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "3096303  4471817.0  2016.0     4.0   745.0   745.0     PHU  20567.0      3.0   \n",
       "3096304  4471819.0  2016.0     4.0   745.0   745.0     PHU  20567.0      3.0   \n",
       "3096305  5011591.0  2016.0     4.0   745.0   745.0     SKA  20570.0      3.0   \n",
       "3096306  4249464.0  2016.0     4.0   745.0   745.0     SUM  20566.0      3.0   \n",
       "3096307  5416391.0  2016.0     4.0   745.0   745.0     SUM  20572.0      3.0   \n",
       "3096308   625229.0  2016.0     4.0   745.0   745.0     SYS  20547.0      3.0   \n",
       "3096309  1972204.0  2016.0     4.0   745.0   745.0     SYS  20554.0      3.0   \n",
       "3096310  4249448.0  2016.0     4.0   745.0   745.0     TEC  20566.0      3.0   \n",
       "3096311  5658953.0  2016.0     4.0   748.0   748.0     NEW  20573.0      3.0   \n",
       "3096312  3106671.0  2016.0     4.0   123.0   749.0     NOG  20561.0      3.0   \n",
       "\n",
       "        i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "3096303      IL  20569.0   ...         NaN        M   1958.0  10222016      F   \n",
       "3096304      IL  20569.0   ...         NaN        M   1969.0  10222016      F   \n",
       "3096305      US  20573.0   ...         NaN        M   1987.0  10182016      F   \n",
       "3096306      CA  20571.0   ...         NaN        M   1978.0  10212016      M   \n",
       "3096307      MN  20577.0   ...         NaN        M   1971.0  10262016      M   \n",
       "3096308      CA      NaN   ...         NaN      NaN   1980.0  05082016    NaN   \n",
       "3096309      CA  20555.0   ...         NaN        M   1980.0  09102016      F   \n",
       "3096310      VA  20588.0   ...         NaN        M   1993.0  09202016      F   \n",
       "3096311      MN      NaN   ...         NaN      NaN   1959.0  10282016      M   \n",
       "3096312      AZ  20567.0   ...         NaN        M   1958.0  07102016      M   \n",
       "\n",
       "        insnum airline        admnum  fltno visatype  \n",
       "3096303    NaN     NaN  9.429629e+10   LAND       B2  \n",
       "3096304    NaN     NaN  9.429643e+10   LAND       B2  \n",
       "3096305    NaN     NaN  9.397554e+10  00490       B1  \n",
       "3096306    NaN     NaN  9.426909e+10   LAND       B1  \n",
       "3096307    NaN     NaN  9.471480e+10   LAND       B1  \n",
       "3096308    NaN     NaN  7.893456e+10  00066       B2  \n",
       "3096309    NaN     NaN  9.030054e+10  00066       B2  \n",
       "3096310    NaN     NaN  9.141672e+10  00651       B2  \n",
       "3096311    NaN     NaN  9.488710e+10   LAND       B2  \n",
       "3096312    NaN     NaN  5.605687e+10  00866       WB  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3096313 entries, 0 to 3096312\n",
      "Data columns (total 28 columns):\n",
      "cicid       float64\n",
      "i94yr       float64\n",
      "i94mon      float64\n",
      "i94cit      float64\n",
      "i94res      float64\n",
      "i94port     object\n",
      "arrdate     float64\n",
      "i94mode     float64\n",
      "i94addr     object\n",
      "depdate     float64\n",
      "i94bir      float64\n",
      "i94visa     float64\n",
      "count       float64\n",
      "dtadfile    object\n",
      "visapost    object\n",
      "occup       object\n",
      "entdepa     object\n",
      "entdepd     object\n",
      "entdepu     object\n",
      "matflag     object\n",
      "biryear     float64\n",
      "dtaddto     object\n",
      "gender      object\n",
      "insnum      object\n",
      "airline     object\n",
      "admnum      float64\n",
      "fltno       object\n",
      "visatype    object\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 661.4+ MB\n"
     ]
    }
   ],
   "source": [
    "imm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean data and keep relevant columns\n",
    "\n",
    "imm_df2 = df_spark[['cicid','i94yr','i94mon','i94port','i94mode','arrdate','depdate','i94bir','biryear','gender', 'i94visa']]\n",
    "\n",
    "imm_df3 = imm_df2.limit(6000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    2899\n",
       "F    2882\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df3.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert dates from Sas to Pyspark\n",
    "\n",
    "@udf(StringType())\n",
    "def convert_dataframe(file):\n",
    "    if file:\n",
    "        return (datetime(1960,1,1).date()+timedelta(file).isoformat())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2682044"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non values\n",
    "imm_df4 = imm_df2.dropna(how = 'any', subset = ['i94port','gender'])\n",
    "imm_df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create cleaned immigration table\n",
    "imm_df5 = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                        col(\"i94yr\").alias(\"year\"),\n",
    "                        col(\"i94mon\").alias(\"month\"),\n",
    "                        col(\"i94port\").alias(\"city_code\"),\n",
    "                        col(\"i94mode\").alias(\"travel_code\"),\n",
    "                        col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                        col(\"depdate\").alias(\"departure_date\"),\n",
    "                        col(\"i94bir\").alias(\"age\"),\n",
    "                        col(\"biryear\").alias(\"birth_year\"),\n",
    "                        col(\"gender\").alias(\"gender\"),\n",
    "                        col(\"i94visa\").alias(\"travel_reason\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>city_code</th>\n",
       "      <th>travel_code</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>travel_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    year  month city_code  travel_code  arrival_date  \\\n",
       "0  5748517.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "1  5748518.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "2  5748519.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "3  5748520.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "4  5748521.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "\n",
       "   departure_date   age  birth_year gender  travel_reason  \n",
       "0         20582.0  40.0      1976.0      F            1.0  \n",
       "1         20591.0  32.0      1984.0      F            1.0  \n",
       "2         20582.0  29.0      1987.0      M            1.0  \n",
       "3         20588.0  29.0      1987.0      F            1.0  \n",
       "4         20588.0  28.0      1988.0      M            1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_clean = imm_df5.limit(6000).toPandas()\n",
    "df_immigration_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2 Temperature data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dt='1743-11-01', AverageTemperature='6.068', AverageTemperatureUncertainty='1.7369999999999999', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1743-12-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-01-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-02-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-03-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-04-01', AverageTemperature='5.7879999999999985', AverageTemperatureUncertainty='3.6239999999999997', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-05-01', AverageTemperature='10.644', AverageTemperatureUncertainty='1.2830000000000001', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-06-01', AverageTemperature='14.050999999999998', AverageTemperatureUncertainty='1.347', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-07-01', AverageTemperature='16.082', AverageTemperatureUncertainty='1.396', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-08-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean country variable\n",
    "temp_df1 = temp_df.filter(temp_df[\"Country\"] == 'United States')\n",
    "\n",
    "# Separate year and month\n",
    "temp_df2 = temp_df1.withColumn(\"year\", year(temp_df['dt'])) \\\n",
    "                                   .withColumn(\"month\", month(temp_df[\"dt\"]))\n",
    "\n",
    "# clean data and keep relevant columns\n",
    "temp_df3 = temp_df2[['City','Country','Latitude','Longitude','AverageTemperature','year','month']]\n",
    "temp_df4 = temp_df3.withColumn('AverageTemperature', col('AverageTemperature').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(max(year)=2013)\n"
     ]
    }
   ],
   "source": [
    "# identify the most recent year of the temperature data because this is most relevant\n",
    "max_yr = temp_df4.agg({\"year\":\"max\"}).collect()[0]\n",
    "print(max_yr)\n",
    "\n",
    "# only keep 2013 data\n",
    "temp_df5 = temp_df4.filter(temp_df4[\"year\"] == 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "print(len(valid_ports))\n",
    "\n",
    "@udf(StringType())\n",
    "def city_abb(city):\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key].lower():\n",
    "            return key\n",
    "        \n",
    "# Create City code\n",
    "temp_df6 = temp_df5.withColumn(\"city_code\", city_abb(temp_df5[\"City\"]))\n",
    "temp_df7 = temp_df6.dropna(how = 'any',subset=['city_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean temp table\n",
    "temp_df8 = temp_df7.select(col(\"City\").alias(\"city\"),\n",
    "                           col(\"city_code\").alias(\"city_code\"),\n",
    "                           col(\"Country\").alias(\"country\"),\n",
    "                           col(\"year\").alias(\"year\"),\n",
    "                           col(\"month\").alias(\"month\"),\n",
    "                           col(\"Latitude\").alias(\"latitude\"),\n",
    "                           col(\"Longitude\").alias(\"longitude\"),\n",
    "                           col(\"AverageTemperature\").alias(\"average_temperature\")\n",
    "                          ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchorage</td>\n",
       "      <td>ANC</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ATL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>83.68W</td>\n",
       "      <td>5.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burbank</td>\n",
       "      <td>BUR</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>118.70W</td>\n",
       "      <td>9.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>DAL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>96.70W</td>\n",
       "      <td>12.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>FTL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>26.52N</td>\n",
       "      <td>80.60W</td>\n",
       "      <td>24.280001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city city_code        country  year  month latitude longitude  \\\n",
       "0        Anchorage       ANC  United States  2013      9   61.88N   151.13W   \n",
       "1          Atlanta       ATL  United States  2013      2   34.56N    83.68W   \n",
       "2          Burbank       BUR  United States  2013      2   34.56N   118.70W   \n",
       "3           Dallas       DAL  United States  2013      3   32.95N    96.70W   \n",
       "4  Fort Lauderdale       FTL  United States  2013      4   26.52N    80.60W   \n",
       "\n",
       "   average_temperature  \n",
       "0                  NaN  \n",
       "1             5.758000  \n",
       "2             9.804000  \n",
       "3            12.543000  \n",
       "4            24.280001  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_clean = temp_df8.limit(6000).toPandas()\n",
    "df_temp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.3 Demographic data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demog_df1 = demog_df.withColumn(\"percentage_males\", (demog_df['Male Population'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_females\", (demog_df['Female Population'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_foreign_born\", (demog_df['Foreign-born'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_race\", (demog_df['Count'] / demog_df['Total Population']))\n",
    "\n",
    "demog_df2 = demog_df1.withColumn(\"city_code\", city_abb(demog_df1[\"City\"]))\n",
    "demog_df3 = demog_df2.dropna(how = 'any',subset=['city_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create cleaned demographic table \n",
    "demog_df4 = demog_df3.select(col(\"City\").alias(\"city\"),\n",
    "                             col(\"city_code\").alias(\"city_code\"),\n",
    "                                  col(\"Race\").alias(\"race\"),\n",
    "                                  col(\"percentage_males\").alias(\"percentage_males\"),\n",
    "                                  col(\"percentage_females\").alias(\"percentage_females\"),\n",
    "                                  col(\"percentage_foreign_born\").alias(\"percentage_foreign_born\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_code</th>\n",
       "      <th>race</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>percentage_foreign_born</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>NEW</td>\n",
       "      <td>White</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.510345</td>\n",
       "      <td>0.305956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>PIA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.526137</td>\n",
       "      <td>0.063349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PHI</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.527083</td>\n",
       "      <td>0.131003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>FMY</td>\n",
       "      <td>White</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.207593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>LCB</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.485967</td>\n",
       "      <td>0.514033</td>\n",
       "      <td>0.267513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city city_code                               race  \\\n",
       "0        Newark       NEW                              White   \n",
       "1        Peoria       PIA  American Indian and Alaska Native   \n",
       "2  Philadelphia       PHI                              Asian   \n",
       "3    Fort Myers       FMY                              White   \n",
       "4        Laredo       LCB  American Indian and Alaska Native   \n",
       "\n",
       "   percentage_males  percentage_females  percentage_foreign_born  \n",
       "0          0.489655            0.510345                 0.305956  \n",
       "1          0.473863            0.526137                 0.063349  \n",
       "2          0.472917            0.527083                 0.131003  \n",
       "3          0.497872            0.502128                 0.207593  \n",
       "4          0.485967            0.514033                 0.267513  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog_clean = demog_df4.limit(6000).toPandas()\n",
    "df_demog_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "Fact table will contain information from the I94 immigration data joined with the city temperature data on i94port and demographic data on:\n",
    "\n",
    "fact_df\n",
    "* id\n",
    "* city_code\n",
    "\n",
    "\n",
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "\n",
    "immigration_df\n",
    "* id\n",
    "* city_code\n",
    "* year\n",
    "* month\n",
    "* arrival_date\n",
    "* departure_date\n",
    "* birth_year\n",
    "* age\n",
    "* gender\n",
    "* travel_reason\n",
    "\n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "\n",
    "temperature_df\n",
    "* city_code\n",
    "* average_temperature\n",
    "* city\n",
    "* country\n",
    "* latitude\n",
    "* longitude\n",
    "* year\n",
    "* month\n",
    "\n",
    "The third dimension table will contain demongraphic data. The columns below will be extracted from the demographic dataframe:\n",
    "\n",
    "demographic_df\n",
    "* city_code\n",
    "* city\n",
    "* race\n",
    "* percentage_males\n",
    "* percentage_females\n",
    "* percentage_foreign_born\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are described below:\n",
    "\n",
    "* Clean I94 data as described in step 2 to create Spark dataframe df_immigration for each month\n",
    "* Clean temperature data as described in step 2 to create Spark dataframe df_temp (already performed)\n",
    "* Create immigration dimension table \n",
    "* Create temperature dimension table\n",
    "* Create demographic dimension table\n",
    "* Create fact table by joining immigration, temperature dimension table and demographic tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First dimension table\n",
    "immigration_df = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                                col(\"i94port\").alias(\"city_code\"),\n",
    "                                col(\"i94yr\").alias(\"year\"),\n",
    "                                col(\"i94mon\").alias(\"month\"),\n",
    "                                col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                                col(\"depdate\").alias(\"departure_date\"),\n",
    "                                col(\"i94bir\").alias(\"age\"),\n",
    "                                col(\"biryear\").alias(\"birth_year\"),\n",
    "                                col(\"gender\").alias(\"gender\"),\n",
    "                                col(\"i94visa\").alias(\"travel_reason\")\n",
    "                               )\n",
    "\n",
    "\n",
    "# Seconf dimension table\n",
    "temperature_df = temp_df7.select(col(\"city_code\").alias(\"city_code\"),\n",
    "                                 col(\"AverageTemperature\").alias(\"average_temperature\"),\n",
    "                                 col(\"City\").alias(\"city\"),\n",
    "                                 col(\"Country\").alias(\"country\"),\n",
    "                                 col(\"Latitude\").alias(\"latitude\"),\n",
    "                                 col(\"Longitude\").alias(\"longitude\"),\n",
    "                                 col(\"year\").alias(\"year\"),\n",
    "                                 col(\"month\").alias(\"month\")\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "# Third dimension table\n",
    "demographic_df = demog_df3.select(col(\"city_code\").alias(\"city_code\"),\n",
    "                                  col(\"City\").alias(\"city\"),\n",
    "                                  col(\"Race\").alias(\"race\"),\n",
    "                                  col(\"percentage_males\").alias(\"percentage_males\"),\n",
    "                                  col(\"percentage_females\").alias(\"percentage_females\"),\n",
    "                                  col(\"percentage_foreign_born\").alias(\"percentage_foreign_born\"))\n",
    "\n",
    "\n",
    "\n",
    "# Fact table\n",
    "fact_df = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                         col(\"i94port\").alias(\"city_code\")\n",
    "                        ).drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=5748517.0, city_code='LOS', year=2016.0, month=4.0, arrival_date=20574.0, departure_date=20582.0, age=40.0, birth_year=1976.0, gender='F', travel_reason=1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(city_code='AKR', average_temperature=-1.0859999656677246, city='Akron', country='United States', latitude='40.99N', longitude='80.95W', year=2013, month=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(city_code='NEW', city='Newark', race='White', percentage_males=0.48965460975549197, percentage_females=0.5103453902445081, percentage_foreign_born=0.30595609283715186)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=5749258.0, city_code='CLT')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 2682044 records\n",
      "Data quality check passed for temperature table with 8599212 records\n",
      "Data quality check passed for demographic table with 2891 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    \n",
    "    Output: Print outcome of data quality check\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(immigration_df, \"immigration table\")\n",
    "quality_check(temp_df, \"temperature table\")\n",
    "quality_check(demog_df, \"demographic table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "This project is to give a chance to combine what I've learned throughout this programme. In the project, I read data from different forms in the jupyter Notebook, assessed and cleaned the data as part of the data wrangling, and createed the ETL pipeline to create a database for useful insights and analysis. \n",
    "\n",
    "I used the star schema with Spark because this database is relatively simple and easy to build. With star schema, it is easy to be understand, denormalized and do fast aggregations.\n",
    "The business questions can be, for example, is there any immigration age distribtuion? or do immigrates prefer warmer places? is there any gender trend for immigration? etc. \n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "The data should be updated at least once a month because 1) i94 and temp datasets are both recorded in monthly basis; 2) the data size will be large if updating less frequent than a month; 3) business demands. \n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "     * The data was increased by 100x\n",
    "     \n",
    "1) Discuss with the business analyst on how they would want to use the data and then decide if I need to adjust the star scheme structure. 2) Move the database to AWS and increase EMR cluster size. Apache Spark is linearly scalable so I can add the number of clusters to increase the performance. With AWS EMR I can adjust the size and number of clusters to fit the database. \n",
    "\n",
    "     * The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "     \n",
    "1) Set up a DAG to update the database every hour to get the database ready for the dashboard. \n",
    "2) Create data quality operators to trigger sending emails if the DAG fails to run.\n",
    "3) Combine Airflow + Spark + Apache Livy in the EMR cluster so that Spark commands can be passed through an API interface. \n",
    "\n",
    "     * The database needed to be accessed by 100+ people\n",
    "     \n",
    "1) Use Redshift to wuto-scaling capabilities of the database.\n",
    "2) If the useers do not need to perform insert and update and they only need to access some queries, the data can be periodically copied to a NoSQL server such as Cassandra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
