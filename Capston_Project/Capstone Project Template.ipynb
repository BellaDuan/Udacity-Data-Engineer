{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US Immigration and Temperature\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This capstone project is to give a chance to combine what I've learned throughout this programme. The project is to create the ETL pipeline to create a database for useful insights and analysis. For example, is there any immigration age or nationality distribtuion? or do immigrates prefer warmer places?\n",
    "\n",
    "#### The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd, re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandasql in /opt/conda/lib/python3.6/site-packages (0.7.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.6/site-packages (from pandasql) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: sqlalchemy in /opt/conda/lib/python3.6/site-packages (from pandasql) (1.1.13)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/lib/python3.6/site-packages (from pandasql) (0.23.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->pandasql) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->pandasql) (2017.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas->pandasql) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pandasql import sqldf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 212.4MB 121kB/s eta 0:00:01 1% |▍                               | 2.3MB 16.8MB/s eta 0:00:13    2% |▋                               | 4.4MB 22.3MB/s eta 0:00:10    3% |█▏                              | 7.6MB 20.6MB/s eta 0:00:10    4% |█▎                              | 8.6MB 22.7MB/s eta 0:00:09    5% |█▊                              | 11.7MB 23.1MB/s eta 0:00:09    6% |██                              | 13.8MB 22.0MB/s eta 0:00:10    6% |██▎                             | 14.8MB 22.5MB/s eta 0:00:09    9% |██▉                             | 19.2MB 23.5MB/s eta 0:00:09    9% |███                             | 20.2MB 20.9MB/s eta 0:00:10    10% |███▍                            | 22.2MB 21.7MB/s eta 0:00:09    10% |███▌                            | 23.2MB 22.8MB/s eta 0:00:09    11% |███▋                            | 24.2MB 20.9MB/s eta 0:00:10    11% |███▉                            | 25.3MB 22.8MB/s eta 0:00:09    13% |████▍                           | 29.4MB 20.5MB/s eta 0:00:09    16% |█████▏                          | 34.6MB 21.0MB/s eta 0:00:09    17% |█████▌                          | 36.6MB 22.1MB/s eta 0:00:08    17% |█████▊                          | 37.6MB 20.9MB/s eta 0:00:09    18% |█████▉                          | 38.6MB 20.9MB/s eta 0:00:09    20% |██████▍                         | 42.8MB 21.0MB/s eta 0:00:09    20% |██████▋                         | 43.8MB 20.4MB/s eta 0:00:09    21% |██████▊                         | 44.7MB 22.0MB/s eta 0:00:08    21% |███████                         | 46.7MB 19.8MB/s eta 0:00:09    23% |███████▋                        | 50.7MB 19.8MB/s eta 0:00:09    24% |███████▊                        | 51.6MB 20.5MB/s eta 0:00:08    25% |████████                        | 53.4MB 18.8MB/s eta 0:00:09    25% |████████▏                       | 54.4MB 22.0MB/s eta 0:00:08    26% |████████▎                       | 55.3MB 19.3MB/s eta 0:00:09    26% |████████▌                       | 56.2MB 19.9MB/s eta 0:00:08    27% |████████▊                       | 58.1MB 19.0MB/s eta 0:00:09    27% |█████████                       | 59.0MB 20.3MB/s eta 0:00:08    30% |█████████▊                      | 64.6MB 21.3MB/s eta 0:00:07    30% |█████████▉                      | 65.4MB 20.9MB/s eta 0:00:08    31% |██████████▏                     | 67.2MB 19.0MB/s eta 0:00:08    32% |██████████▎                     | 68.2MB 15.8MB/s eta 0:00:10    32% |██████████▍                     | 69.0MB 17.4MB/s eta 0:00:09    33% |██████████▋                     | 70.7MB 16.8MB/s eta 0:00:09    33% |██████████▉                     | 71.6MB 17.8MB/s eta 0:00:08    34% |███████████                     | 72.6MB 18.4MB/s eta 0:00:08    34% |███████████                     | 73.4MB 20.4MB/s eta 0:00:07    35% |███████████▎                    | 75.2MB 20.2MB/s eta 0:00:07    36% |███████████▋                    | 77.1MB 19.7MB/s eta 0:00:07    36% |███████████▊                    | 77.8MB 19.2MB/s eta 0:00:08    37% |████████████                    | 79.5MB 18.0MB/s eta 0:00:08    38% |████████████▎                   | 81.2MB 17.9MB/s eta 0:00:08    38% |████████████▍                   | 82.1MB 19.1MB/s eta 0:00:07    39% |████████████▋                   | 83.8MB 19.1MB/s eta 0:00:07    40% |████████████▉                   | 85.1MB 4.5MB/s eta 0:00:29    40% |█████████████                   | 85.9MB 20.9MB/s eta 0:00:07    40% |█████████████                   | 86.9MB 17.6MB/s eta 0:00:08    41% |█████████████▎                  | 87.8MB 20.2MB/s eta 0:00:07    42% |█████████████▌                  | 89.7MB 18.5MB/s eta 0:00:07    43% |█████████████▉                  | 91.6MB 18.3MB/s eta 0:00:07    43% |██████████████                  | 93.2MB 17.1MB/s eta 0:00:07    44% |██████████████▎                 | 94.8MB 18.5MB/s eta 0:00:07    45% |██████████████▌                 | 96.5MB 21.9MB/s eta 0:00:06    45% |██████████████▊                 | 97.5MB 17.7MB/s eta 0:00:07    46% |██████████████▉                 | 98.3MB 17.8MB/s eta 0:00:07    46% |███████████████                 | 99.3MB 20.4MB/s eta 0:00:06    47% |███████████████                 | 100.1MB 13.8MB/s eta 0:00:09    47% |███████████████▏                | 100.9MB 18.9MB/s eta 0:00:06    48% |███████████████▍                | 102.3MB 16.5MB/s eta 0:00:07    49% |███████████████▉                | 104.8MB 19.1MB/s eta 0:00:06    49% |████████████████                | 105.7MB 14.8MB/s eta 0:00:08    51% |████████████████▍               | 108.5MB 9.3MB/s eta 0:00:12    53% |█████████████████▏              | 113.8MB 15.7MB/s eta 0:00:07    53% |█████████████████▎              | 114.7MB 21.0MB/s eta 0:00:05    54% |█████████████████▍              | 115.7MB 20.2MB/s eta 0:00:05    54% |█████████████████▋              | 116.7MB 20.4MB/s eta 0:00:05    55% |█████████████████▊              | 117.8MB 19.5MB/s eta 0:00:05    56% |██████████████████              | 119.7MB 22.1MB/s eta 0:00:05    57% |██████████████████▎             | 121.5MB 12.2MB/s eta 0:00:08    58% |██████████████████▊             | 124.0MB 22.1MB/s eta 0:00:05    58% |██████████████████▉             | 124.9MB 16.7MB/s eta 0:00:06    59% |███████████████████             | 125.9MB 18.8MB/s eta 0:00:05    59% |███████████████████             | 126.8MB 16.1MB/s eta 0:00:06    60% |███████████████████▎            | 127.8MB 21.9MB/s eta 0:00:04    60% |███████████████████▍            | 128.7MB 17.6MB/s eta 0:00:05    60% |███████████████████▌            | 129.6MB 15.9MB/s eta 0:00:06    61% |███████████████████▋            | 130.6MB 22.5MB/s eta 0:00:04    62% |████████████████████            | 132.5MB 25.1MB/s eta 0:00:04    62% |████████████████████▏           | 133.5MB 20.8MB/s eta 0:00:04    63% |████████████████████▎           | 134.6MB 21.6MB/s eta 0:00:04    63% |████████████████████▍           | 135.7MB 20.3MB/s eta 0:00:04    64% |████████████████████▋           | 136.8MB 22.9MB/s eta 0:00:04    64% |████████████████████▊           | 137.7MB 17.7MB/s eta 0:00:05    65% |█████████████████████           | 139.7MB 21.2MB/s eta 0:00:04    66% |█████████████████████▎          | 141.5MB 17.8MB/s eta 0:00:04    67% |█████████████████████▋          | 143.4MB 20.9MB/s eta 0:00:04    68% |██████████████████████          | 146.3MB 17.5MB/s eta 0:00:04    69% |██████████████████████▎         | 148.1MB 18.5MB/s eta 0:00:04    70% |██████████████████████▌         | 149.1MB 20.6MB/s eta 0:00:04    70% |██████████████████████▋         | 150.2MB 23.7MB/s eta 0:00:03    71% |██████████████████████▉         | 151.3MB 23.1MB/s eta 0:00:03    71% |███████████████████████         | 152.4MB 21.3MB/s eta 0:00:03    72% |███████████████████████▎        | 154.2MB 17.9MB/s eta 0:00:04    73% |███████████████████████▋        | 157.0MB 25.8MB/s eta 0:00:03    75% |████████████████████████        | 159.9MB 20.0MB/s eta 0:00:03    75% |████████████████████████▎       | 160.8MB 17.4MB/s eta 0:00:03    76% |████████████████████████▍       | 161.6MB 17.2MB/s eta 0:00:03    76% |████████████████████████▌       | 162.7MB 23.7MB/s eta 0:00:03    77% |████████████████████████▉       | 164.6MB 25.0MB/s eta 0:00:02    78% |█████████████████████████       | 166.5MB 16.0MB/s eta 0:00:03    78% |█████████████████████████▏      | 167.4MB 16.6MB/s eta 0:00:03    79% |█████████████████████████▍      | 168.3MB 18.9MB/s eta 0:00:03    79% |█████████████████████████▌      | 169.2MB 18.1MB/s eta 0:00:03    80% |█████████████████████████▋      | 170.1MB 19.0MB/s eta 0:00:03    80% |█████████████████████████▊      | 171.1MB 21.6MB/s eta 0:00:02    81% |██████████████████████████      | 172.2MB 22.5MB/s eta 0:00:02    81% |██████████████████████████▏     | 173.4MB 24.9MB/s eta 0:00:02    82% |██████████████████████████▎     | 174.4MB 23.3MB/s eta 0:00:02    82% |██████████████████████████▍     | 175.5MB 22.9MB/s eta 0:00:02    83% |██████████████████████████▋     | 176.6MB 25.5MB/s eta 0:00:02    83% |██████████████████████████▊     | 177.6MB 16.0MB/s eta 0:00:03    84% |███████████████████████████     | 178.6MB 19.5MB/s eta 0:00:02    84% |███████████████████████████     | 179.6MB 17.0MB/s eta 0:00:02    85% |███████████████████████████▏    | 180.6MB 24.2MB/s eta 0:00:02    85% |███████████████████████████▍    | 181.7MB 20.5MB/s eta 0:00:02    85% |███████████████████████████▌    | 182.6MB 17.5MB/s eta 0:00:02    86% |███████████████████████████▋    | 183.6MB 22.2MB/s eta 0:00:02    87% |████████████████████████████    | 186.5MB 12.1MB/s eta 0:00:03    88% |████████████████████████████▎   | 187.5MB 18.4MB/s eta 0:00:02    88% |████████████████████████████▍   | 188.4MB 18.1MB/s eta 0:00:02    89% |████████████████████████████▌   | 189.4MB 20.9MB/s eta 0:00:02    89% |████████████████████████████▊   | 190.4MB 17.8MB/s eta 0:00:02    90% |████████████████████████████▉   | 191.5MB 22.9MB/s eta 0:00:01    90% |█████████████████████████████   | 192.5MB 16.0MB/s eta 0:00:02    91% |█████████████████████████████▏  | 193.5MB 28.2MB/s eta 0:00:01    91% |█████████████████████████████▎  | 194.5MB 17.6MB/s eta 0:00:02    91% |█████████████████████████████▍  | 195.4MB 16.8MB/s eta 0:00:02    92% |█████████████████████████████▌  | 196.1MB 6.9MB/s eta 0:00:03    92% |█████████████████████████████▋  | 196.8MB 13.1MB/s eta 0:00:02    93% |█████████████████████████████▉  | 198.1MB 9.4MB/s eta 0:00:02    94% |██████████████████████████████▏ | 200.5MB 19.5MB/s eta 0:00:01    94% |██████████████████████████████▍ | 201.5MB 22.6MB/s eta 0:00:01    95% |██████████████████████████████▌ | 202.5MB 17.5MB/s eta 0:00:01    95% |██████████████████████████████▋ | 203.4MB 18.7MB/s eta 0:00:01    96% |██████████████████████████████▉ | 204.5MB 23.1MB/s eta 0:00:01    97% |███████████████████████████████▏| 206.7MB 17.8MB/s eta 0:00:01    97% |███████████████████████████████▎| 207.6MB 17.0MB/s eta 0:00:01    98% |███████████████████████████████▍| 208.4MB 18.3MB/s eta 0:00:01    98% |███████████████████████████████▌| 209.5MB 24.5MB/s eta 0:00:01    99% |███████████████████████████████▊| 210.7MB 25.4MB/s eta 0:00:01    99% |███████████████████████████████▉| 211.7MB 16.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.9 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 17.3MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "  Found existing installation: py4j 0.10.7\n",
      "    Uninstalling py4j-0.10.7:\n",
      "      Successfully uninstalled py4j-0.10.7\n",
      "  Found existing installation: pyspark 2.4.3\n",
      "    Can't uninstall 'pyspark'. No files were found to uninstall.\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark --upgrade\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, count, col, year, month, avg, isnull, round\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_spark =spark.read.load('./sas_data')\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "3 different sources will be used to create fact and dimension tables. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "- I94 Immigration Data: comes from the U.S. National Tourism and Trade Office and contains various statistics on international visitor arrival in USA and comes from the US National Tourism and Trade Office. ([link](https://www.trade.gov/national-travel-and-tourism-office)).\n",
    "- World Temperature Data: This dataset came from Kaggle and includes the information about the average weather temperatures. ([link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)).\n",
    "- U.S. City Demographic Data: This data comes from OpenSoft and includes the information about the demographics of US cities such as average age, gender distribution. ([link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the I94 immigration data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "imm_df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "\n",
       "  airline        admnum fltno visatype  \n",
       "0     NaN  1.897628e+09   NaN       B2  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the temperature data here\n",
    "temp_fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temp_df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(temp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dt='1743-11-01', AverageTemperature='6.068', AverageTemperatureUncertainty='1.7369999999999999', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the demographic data here\n",
    "demog_fname = 'us-cities-demographics.csv'\n",
    "demog_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(demog_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 i94 Immigration data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247161e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247080e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247849e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MI   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "7   20.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "8   21.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "9   22.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "5  20555.0   ...         NaN        M   1959.0  09302016    NaN    NaN   \n",
       "6  20558.0   ...         NaN        M   1953.0  09302016    NaN    NaN   \n",
       "7  20558.0   ...         NaN        M   1959.0  09302016    NaN    NaN   \n",
       "8  20553.0   ...         NaN        M   1970.0  09302016    NaN    NaN   \n",
       "9  20562.0   ...         NaN        M   1968.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "5      AZ  9.247104e+10  00602       B1  \n",
       "6      AZ  9.247140e+10  00602       B2  \n",
       "7      AZ  9.247161e+10  00602       B2  \n",
       "8      AZ  9.247080e+10  00602       B2  \n",
       "9      AZ  9.247849e+10  00608       B1  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3096303</th>\n",
       "      <td>4471817.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>PHU</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429629e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096304</th>\n",
       "      <td>4471819.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>PHU</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429643e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096305</th>\n",
       "      <td>5011591.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SKA</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10182016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.397554e+10</td>\n",
       "      <td>00490</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096306</th>\n",
       "      <td>4249464.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SUM</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>10212016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.426909e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096307</th>\n",
       "      <td>5416391.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SUM</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MN</td>\n",
       "      <td>20577.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>10262016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.471480e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096308</th>\n",
       "      <td>625229.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SYS</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>05082016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.893456e+10</td>\n",
       "      <td>00066</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096309</th>\n",
       "      <td>1972204.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>SYS</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>09102016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.030054e+10</td>\n",
       "      <td>00066</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096310</th>\n",
       "      <td>4249448.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>745.0</td>\n",
       "      <td>TEC</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>09202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.141672e+10</td>\n",
       "      <td>00651</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096311</th>\n",
       "      <td>5658953.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.488710e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096312</th>\n",
       "      <td>3106671.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>NOG</td>\n",
       "      <td>20561.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>07102016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.605687e+10</td>\n",
       "      <td>00866</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "3096303  4471817.0  2016.0     4.0   745.0   745.0     PHU  20567.0      3.0   \n",
       "3096304  4471819.0  2016.0     4.0   745.0   745.0     PHU  20567.0      3.0   \n",
       "3096305  5011591.0  2016.0     4.0   745.0   745.0     SKA  20570.0      3.0   \n",
       "3096306  4249464.0  2016.0     4.0   745.0   745.0     SUM  20566.0      3.0   \n",
       "3096307  5416391.0  2016.0     4.0   745.0   745.0     SUM  20572.0      3.0   \n",
       "3096308   625229.0  2016.0     4.0   745.0   745.0     SYS  20547.0      3.0   \n",
       "3096309  1972204.0  2016.0     4.0   745.0   745.0     SYS  20554.0      3.0   \n",
       "3096310  4249448.0  2016.0     4.0   745.0   745.0     TEC  20566.0      3.0   \n",
       "3096311  5658953.0  2016.0     4.0   748.0   748.0     NEW  20573.0      3.0   \n",
       "3096312  3106671.0  2016.0     4.0   123.0   749.0     NOG  20561.0      3.0   \n",
       "\n",
       "        i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "3096303      IL  20569.0   ...         NaN        M   1958.0  10222016      F   \n",
       "3096304      IL  20569.0   ...         NaN        M   1969.0  10222016      F   \n",
       "3096305      US  20573.0   ...         NaN        M   1987.0  10182016      F   \n",
       "3096306      CA  20571.0   ...         NaN        M   1978.0  10212016      M   \n",
       "3096307      MN  20577.0   ...         NaN        M   1971.0  10262016      M   \n",
       "3096308      CA      NaN   ...         NaN      NaN   1980.0  05082016    NaN   \n",
       "3096309      CA  20555.0   ...         NaN        M   1980.0  09102016      F   \n",
       "3096310      VA  20588.0   ...         NaN        M   1993.0  09202016      F   \n",
       "3096311      MN      NaN   ...         NaN      NaN   1959.0  10282016      M   \n",
       "3096312      AZ  20567.0   ...         NaN        M   1958.0  07102016      M   \n",
       "\n",
       "        insnum airline        admnum  fltno visatype  \n",
       "3096303    NaN     NaN  9.429629e+10   LAND       B2  \n",
       "3096304    NaN     NaN  9.429643e+10   LAND       B2  \n",
       "3096305    NaN     NaN  9.397554e+10  00490       B1  \n",
       "3096306    NaN     NaN  9.426909e+10   LAND       B1  \n",
       "3096307    NaN     NaN  9.471480e+10   LAND       B1  \n",
       "3096308    NaN     NaN  7.893456e+10  00066       B2  \n",
       "3096309    NaN     NaN  9.030054e+10  00066       B2  \n",
       "3096310    NaN     NaN  9.141672e+10  00651       B2  \n",
       "3096311    NaN     NaN  9.488710e+10   LAND       B2  \n",
       "3096312    NaN     NaN  5.605687e+10  00866       WB  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3096313 entries, 0 to 3096312\n",
      "Data columns (total 28 columns):\n",
      "cicid       float64\n",
      "i94yr       float64\n",
      "i94mon      float64\n",
      "i94cit      float64\n",
      "i94res      float64\n",
      "i94port     object\n",
      "arrdate     float64\n",
      "i94mode     float64\n",
      "i94addr     object\n",
      "depdate     float64\n",
      "i94bir      float64\n",
      "i94visa     float64\n",
      "count       float64\n",
      "dtadfile    object\n",
      "visapost    object\n",
      "occup       object\n",
      "entdepa     object\n",
      "entdepd     object\n",
      "entdepu     object\n",
      "matflag     object\n",
      "biryear     float64\n",
      "dtaddto     object\n",
      "gender      object\n",
      "insnum      object\n",
      "airline     object\n",
      "admnum      float64\n",
      "fltno       object\n",
      "visatype    object\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 661.4+ MB\n"
     ]
    }
   ],
   "source": [
    "imm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean data and keep relevant columns\n",
    "\n",
    "imm_df2 = df_spark[['cicid','i94yr','i94mon','i94port','i94mode','arrdate','depdate','i94bir','biryear','gender', 'i94visa']]\n",
    "\n",
    "imm_df3 = imm_df2.limit(6000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    2899\n",
       "F    2882\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df3.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert dates from Sas to Pyspark\n",
    "\n",
    "@udf(StringType())\n",
    "def convert_dataframe(file):\n",
    "    if file:\n",
    "        return (datetime(1960,1,1).date()+timedelta(file).isoformat())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2682044"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non values\n",
    "imm_df4 = imm_df2.dropna(how = 'any', subset = ['i94port','gender'])\n",
    "imm_df4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create cleaned immigration table\n",
    "imm_df5 = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                        col(\"i94yr\").alias(\"year\"),\n",
    "                        col(\"i94mon\").alias(\"month\"),\n",
    "                        col(\"i94port\").alias(\"city_code\"),\n",
    "                        col(\"i94mode\").alias(\"travel_code\"),\n",
    "                        col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                        col(\"depdate\").alias(\"departure_date\"),\n",
    "                        col(\"i94bir\").alias(\"age\"),\n",
    "                        col(\"biryear\").alias(\"birth_year\"),\n",
    "                        col(\"gender\").alias(\"gender\"),\n",
    "                        col(\"i94visa\").alias(\"travel_reason\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>city_code</th>\n",
       "      <th>travel_code</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>travel_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    year  month city_code  travel_code  arrival_date  \\\n",
       "0  5748517.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "1  5748518.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "2  5748519.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "3  5748520.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "4  5748521.0  2016.0    4.0       LOS          1.0       20574.0   \n",
       "\n",
       "   departure_date   age  birth_year gender  travel_reason  \n",
       "0         20582.0  40.0      1976.0      F            1.0  \n",
       "1         20591.0  32.0      1984.0      F            1.0  \n",
       "2         20582.0  29.0      1987.0      M            1.0  \n",
       "3         20588.0  29.0      1987.0      F            1.0  \n",
       "4         20588.0  28.0      1988.0      M            1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_clean = imm_df5.limit(6000).toPandas()\n",
    "df_immigration_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2 Temperature data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dt='1743-11-01', AverageTemperature='6.068', AverageTemperatureUncertainty='1.7369999999999999', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1743-12-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-01-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-02-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-03-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-04-01', AverageTemperature='5.7879999999999985', AverageTemperatureUncertainty='3.6239999999999997', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-05-01', AverageTemperature='10.644', AverageTemperatureUncertainty='1.2830000000000001', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-06-01', AverageTemperature='14.050999999999998', AverageTemperatureUncertainty='1.347', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-07-01', AverageTemperature='16.082', AverageTemperatureUncertainty='1.396', City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E'),\n",
       " Row(dt='1744-08-01', AverageTemperature=None, AverageTemperatureUncertainty=None, City='Århus', Country='Denmark', Latitude='57.05N', Longitude='10.33E')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean country variable\n",
    "temp_df1 = temp_df.filter(temp_df[\"Country\"] == 'United States')\n",
    "\n",
    "# Separate year and month\n",
    "temp_df2 = temp_df1.withColumn(\"year\", year(temp_df['dt'])) \\\n",
    "                                   .withColumn(\"month\", month(temp_df[\"dt\"]))\n",
    "\n",
    "# clean data and keep relevant columns\n",
    "temp_df3 = temp_df2[['City','Country','Latitude','Longitude','AverageTemperature','year','month']]\n",
    "temp_df4 = temp_df3.withColumn('AverageTemperature', col('AverageTemperature').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(max(year)=2013)\n"
     ]
    }
   ],
   "source": [
    "# identify the most recent year of the temperature data because this is most relevant\n",
    "max_yr = temp_df4.agg({\"year\":\"max\"}).collect()[0]\n",
    "print(max_yr)\n",
    "\n",
    "# only keep 2013 data\n",
    "temp_df5 = temp_df4.filter(temp_df4[\"year\"] == 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Create City code as the primary key for creating star schema later\n",
    "\n",
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "print(len(valid_ports))\n",
    "\n",
    "@udf(StringType())\n",
    "def city_abb(city):\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key].lower():\n",
    "            return key\n",
    "        \n",
    "temp_df6 = temp_df5.withColumn(\"city_code\", city_abb(temp_df5[\"City\"]))\n",
    "temp_df7 = temp_df6.dropna(how = 'any',subset=['city_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean temp table\n",
    "temp_df8 = temp_df7.select(col(\"City\").alias(\"city\"),\n",
    "                           col(\"city_code\").alias(\"city_code\"),\n",
    "                           col(\"Country\").alias(\"country\"),\n",
    "                           col(\"year\").alias(\"year\"),\n",
    "                           col(\"month\").alias(\"month\"),\n",
    "                           col(\"Latitude\").alias(\"latitude\"),\n",
    "                           col(\"Longitude\").alias(\"longitude\"),\n",
    "                           col(\"AverageTemperature\").alias(\"average_temperature\")\n",
    "                          ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchorage</td>\n",
       "      <td>ANC</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>61.88N</td>\n",
       "      <td>151.13W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ATL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>83.68W</td>\n",
       "      <td>5.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burbank</td>\n",
       "      <td>BUR</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>118.70W</td>\n",
       "      <td>9.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>DAL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>96.70W</td>\n",
       "      <td>12.543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>FTL</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>26.52N</td>\n",
       "      <td>80.60W</td>\n",
       "      <td>24.280001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city city_code        country  year  month latitude longitude  \\\n",
       "0        Anchorage       ANC  United States  2013      9   61.88N   151.13W   \n",
       "1          Atlanta       ATL  United States  2013      2   34.56N    83.68W   \n",
       "2          Burbank       BUR  United States  2013      2   34.56N   118.70W   \n",
       "3           Dallas       DAL  United States  2013      3   32.95N    96.70W   \n",
       "4  Fort Lauderdale       FTL  United States  2013      4   26.52N    80.60W   \n",
       "\n",
       "   average_temperature  \n",
       "0                  NaN  \n",
       "1             5.758000  \n",
       "2             9.804000  \n",
       "3            12.543000  \n",
       "4            24.280001  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_clean = temp_df8.limit(6000).toPandas()\n",
    "df_temp_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.3 Demographic data exploration, assessment and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Silver Spring', State='Maryland', Median Age='33.8', Male Population='40601', Female Population='41862', Total Population='82463', Number of Veterans='1562', Foreign-born='30908', Average Household Size='2.6', State Code='MD', Race='Hispanic or Latino', Count='25924')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculate the most relevant insights and build into the database directly\n",
    "demog_df1 = demog_df.withColumn(\"percentage_males\", (demog_df['Male Population'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_females\", (demog_df['Female Population'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_foreign_born\", (demog_df['Foreign-born'] / demog_df['Total Population'])) \\\n",
    "                    .withColumn(\"percentage_race\", (demog_df['Count'] / demog_df['Total Population']))\n",
    "# add city_code to demog_df for dimension table later\n",
    "demog_df2 = demog_df1.withColumn(\"city_code\", city_abb(demog_df1[\"City\"]))\n",
    "demog_df3 = demog_df2.dropna(how = 'any',subset=['city_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create cleaned demographic table \n",
    "demog_df4 = demog_df3.select(col(\"City\").alias(\"city\"),\n",
    "                             col(\"city_code\").alias(\"city_code\"),\n",
    "                                  col(\"Race\").alias(\"race\"),\n",
    "                                  col(\"percentage_males\").alias(\"percentage_males\"),\n",
    "                                  col(\"percentage_females\").alias(\"percentage_females\"),\n",
    "                                  col(\"percentage_foreign_born\").alias(\"percentage_foreign_born\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_code</th>\n",
       "      <th>race</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>percentage_foreign_born</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>NEW</td>\n",
       "      <td>White</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.510345</td>\n",
       "      <td>0.305956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>PIA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.526137</td>\n",
       "      <td>0.063349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PHI</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.527083</td>\n",
       "      <td>0.131003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>FMY</td>\n",
       "      <td>White</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.207593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>LCB</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.485967</td>\n",
       "      <td>0.514033</td>\n",
       "      <td>0.267513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city city_code                               race  \\\n",
       "0        Newark       NEW                              White   \n",
       "1        Peoria       PIA  American Indian and Alaska Native   \n",
       "2  Philadelphia       PHI                              Asian   \n",
       "3    Fort Myers       FMY                              White   \n",
       "4        Laredo       LCB  American Indian and Alaska Native   \n",
       "\n",
       "   percentage_males  percentage_females  percentage_foreign_born  \n",
       "0          0.489655            0.510345                 0.305956  \n",
       "1          0.473863            0.526137                 0.063349  \n",
       "2          0.472917            0.527083                 0.131003  \n",
       "3          0.497872            0.502128                 0.207593  \n",
       "4          0.485967            0.514033                 0.267513  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog_clean = demog_df4.limit(6000).toPandas()\n",
    "df_demog_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "Fact table will contain information from the I94 immigration data joined with the city temperature data on i94port and demographic data on:\n",
    "\n",
    "fact_df\n",
    "* id\n",
    "* city_code\n",
    "\n",
    "\n",
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "\n",
    "immigration_df\n",
    "* id\n",
    "* city_code\n",
    "* year\n",
    "* month\n",
    "* arrival_date\n",
    "* departure_date\n",
    "* birth_year\n",
    "* age\n",
    "* gender\n",
    "* travel_reason\n",
    "\n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "\n",
    "temperature_df\n",
    "* city_code\n",
    "* average_temperature\n",
    "* city\n",
    "* country\n",
    "* latitude\n",
    "* longitude\n",
    "* year\n",
    "* month\n",
    "\n",
    "The third dimension table will contain demongraphic data. The columns below will be extracted from the demographic dataframe:\n",
    "\n",
    "demographic_df\n",
    "* city_code\n",
    "* city\n",
    "* race\n",
    "* percentage_males\n",
    "* percentage_females\n",
    "* percentage_foreign_born\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are described below:\n",
    "\n",
    "* Clean I94 data as described in step 2 to create Spark dataframe df_immigration for each month\n",
    "* Clean temperature data as described in step 2 to create Spark dataframe df_temp (already performed)\n",
    "* Create immigration dimension table \n",
    "* Create temperature dimension table\n",
    "* Create demographic dimension table\n",
    "* Create fact table by joining immigration, temperature dimension table and demographic tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First dimension table by selecting relevant columns from imm_df4\n",
    "immigration_df = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                                col(\"i94port\").alias(\"city_code\"),\n",
    "                                col(\"i94yr\").alias(\"year\"),\n",
    "                                col(\"i94mon\").alias(\"month\"),\n",
    "                                col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                                col(\"depdate\").alias(\"departure_date\"),\n",
    "                                col(\"i94bir\").alias(\"age\"),\n",
    "                                col(\"biryear\").alias(\"birth_year\"),\n",
    "                                col(\"gender\").alias(\"gender\"),\n",
    "                                col(\"i94visa\").alias(\"travel_reason\")\n",
    "                               )\n",
    "\n",
    "\n",
    "# Seconf dimension table by selecting relevant columns from temp_df7\n",
    "temperature_df = temp_df7.select(col(\"city_code\").alias(\"city_code\"),\n",
    "                                 col(\"AverageTemperature\").alias(\"average_temperature\"),\n",
    "                                 col(\"City\").alias(\"city\"),\n",
    "                                 col(\"Country\").alias(\"country\"),\n",
    "                                 col(\"Latitude\").alias(\"latitude\"),\n",
    "                                 col(\"Longitude\").alias(\"longitude\"),\n",
    "                                 col(\"year\").alias(\"year\"),\n",
    "                                 col(\"month\").alias(\"month\")\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "# Third dimension table by selecting relevant columns from demog_df3\n",
    "demographic_df = demog_df3.select(col(\"city_code\").alias(\"city_code\"),\n",
    "                                  col(\"City\").alias(\"city\"),\n",
    "                                  col(\"Race\").alias(\"race\"),\n",
    "                                  col(\"percentage_males\").alias(\"percentage_males\"),\n",
    "                                  col(\"percentage_females\").alias(\"percentage_females\"),\n",
    "                                  col(\"percentage_foreign_born\").alias(\"percentage_foreign_born\"))\n",
    "\n",
    "\n",
    "\n",
    "# Fact table\n",
    "fact_df = imm_df4.select(col(\"cicid\").alias(\"id\"),\n",
    "                         col(\"i94port\").alias(\"city_code\")\n",
    "                        ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city_code</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>travel_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id city_code    year  month  arrival_date  departure_date   age  \\\n",
       "0  5748517.0       LOS  2016.0    4.0       20574.0         20582.0  40.0   \n",
       "1  5748518.0       LOS  2016.0    4.0       20574.0         20591.0  32.0   \n",
       "2  5748519.0       LOS  2016.0    4.0       20574.0         20582.0  29.0   \n",
       "3  5748520.0       LOS  2016.0    4.0       20574.0         20588.0  29.0   \n",
       "4  5748521.0       LOS  2016.0    4.0       20574.0         20588.0  28.0   \n",
       "\n",
       "   birth_year gender  travel_reason  \n",
       "0      1976.0      F            1.0  \n",
       "1      1984.0      F            1.0  \n",
       "2      1987.0      M            1.0  \n",
       "3      1987.0      F            1.0  \n",
       "4      1988.0      M            1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKR</td>\n",
       "      <td>-1.086</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKR</td>\n",
       "      <td>-2.213</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKR</td>\n",
       "      <td>1.285</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKR</td>\n",
       "      <td>9.691</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AKR</td>\n",
       "      <td>16.789</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code  average_temperature   city        country latitude longitude  \\\n",
       "0       AKR               -1.086  Akron  United States   40.99N    80.95W   \n",
       "1       AKR               -2.213  Akron  United States   40.99N    80.95W   \n",
       "2       AKR                1.285  Akron  United States   40.99N    80.95W   \n",
       "3       AKR                9.691  Akron  United States   40.99N    80.95W   \n",
       "4       AKR               16.789  Akron  United States   40.99N    80.95W   \n",
       "\n",
       "   year  month  \n",
       "0  2013      1  \n",
       "1  2013      2  \n",
       "2  2013      3  \n",
       "3  2013      4  \n",
       "4  2013      5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>city</th>\n",
       "      <th>race</th>\n",
       "      <th>percentage_males</th>\n",
       "      <th>percentage_females</th>\n",
       "      <th>percentage_foreign_born</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW</td>\n",
       "      <td>Newark</td>\n",
       "      <td>White</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.510345</td>\n",
       "      <td>0.305956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIA</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.473863</td>\n",
       "      <td>0.526137</td>\n",
       "      <td>0.063349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHI</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.527083</td>\n",
       "      <td>0.131003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FMY</td>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>White</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.502128</td>\n",
       "      <td>0.207593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCB</td>\n",
       "      <td>Laredo</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>0.485967</td>\n",
       "      <td>0.514033</td>\n",
       "      <td>0.267513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code          city                               race  \\\n",
       "0       NEW        Newark                              White   \n",
       "1       PIA        Peoria  American Indian and Alaska Native   \n",
       "2       PHI  Philadelphia                              Asian   \n",
       "3       FMY    Fort Myers                              White   \n",
       "4       LCB        Laredo  American Indian and Alaska Native   \n",
       "\n",
       "   percentage_males  percentage_females  percentage_foreign_born  \n",
       "0          0.489655            0.510345                 0.305956  \n",
       "1          0.473863            0.526137                 0.063349  \n",
       "2          0.472917            0.527083                 0.131003  \n",
       "3          0.497872            0.502128                 0.207593  \n",
       "4          0.485967            0.514033                 0.267513  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5749258.0</td>\n",
       "      <td>CLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5749308.0</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5749385.0</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5749893.0</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5750350.0</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id city_code\n",
       "0  5749258.0       CLT\n",
       "1  5749308.0       NEW\n",
       "2  5749385.0       NEW\n",
       "3  5749893.0       TOR\n",
       "4  5750350.0       ATL"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Dictionary\n",
    "\n",
    "#### fact_df\n",
    "\n",
    "* id = immigrate id\n",
    "* city_code = 3 digit code of origin city\n",
    "\n",
    "#### immigration_df\n",
    "\n",
    "* id = immigrate id\n",
    "* city_code = 3 digit code of origin city\n",
    "* year = 4 digit year\n",
    "* month = numeric month\n",
    "* arrival_date = arrival date\n",
    "* departure_date = departure date\n",
    "* birth_year = birth year of immigrates\n",
    "* age = age of immigrates\n",
    "* gender = sex of immigrates\n",
    "* travel_reason = reason for immigration\n",
    "\n",
    "\n",
    "#### temperature_df\n",
    "\n",
    "* city_code = 3 digit code of origin city\n",
    "* average_temperature = everage temperature\n",
    "* city = city name\n",
    "* country = country name\n",
    "* latitude = city latitude\n",
    "* longitude = city longitude\n",
    "* year = 4 digit year of the temperature\n",
    "* month = month of the temperature\n",
    "\n",
    "\n",
    "#### demographic_df\n",
    "\n",
    "* city_code = 3 digit code of origin city\n",
    "* city = city name\n",
    "* race = immigrate race\n",
    "* percentage_males = percentage of male immigrates\n",
    "* percentage_females = percentage of female immigrates\n",
    "* percentage_foreign_born = percentage of foregin born immigrates\n",
    "\n",
    "### Mapping out the Data Pipelines\n",
    "The pipeline processes are stated in step 2 &3:\n",
    "1. Clean i94 data\n",
    "2. Clean temperature data\n",
    "3. Clean demographic data\n",
    "4. Create immigration dimension table\n",
    "5. Create temperature dimension table\n",
    "6. Create demographic dimension table\n",
    "7. Create fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 2682044 records\n",
      "Data quality check passed for temperature table with 8599212 records\n",
      "Data quality check passed for demographic table with 2891 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "def quality_check(df, description):\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(immigration_df, \"immigration table\")\n",
    "quality_check(temp_df, \"temperature table\")\n",
    "quality_check(demog_df, \"demographic table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Sample query\n",
    "\n",
    "is there any immigration age distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3b424943b9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mcity_code\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m '''\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmysql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-3b424943b9f9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# quality check with sample query to test that the data model works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmysql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m query = '''\n\u001b[1;32m      5\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36msqldf\u001b[0;34m(query, env, db_uri)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0msqldf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select avg(x) from df;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPandaSQL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, query, env)\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_tables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandasql/sqldf.py\u001b[0m in \u001b[0;36mwrite_table\u001b[0;34m(df, tablename, conn)\u001b[0m\n\u001b[1;32m    119\u001b[0m                        message='The provided table name \\'%s\\' is not found exactly as such in the database' % tablename)\n\u001b[1;32m    120\u001b[0m         to_sql(df, name=tablename, con=conn,\n\u001b[0;32m--> 121\u001b[0;31m                index=not any(name is None for name in df.index.names))  # load index into db if all levels are named\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1300\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# quality check with sample query to test that the data model works \n",
    "mysql = lambda q: sqldf(q, globals())\n",
    "\n",
    "query = '''\n",
    "SELECT city, \n",
    "       count(id) AS population, \n",
    "       avg(age) AS avg_age\n",
    "FROM immigration_df \n",
    "WHERE city_code is not null \n",
    "GROUP BY city_code;\n",
    "'''\n",
    "mysql(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "This project is to give a chance to combine what I've learned throughout this programme. In the project, I read data from different forms in the jupyter Notebook, assessed and cleaned the data as part of the data wrangling, and createed the ETL pipeline to create a database for useful insights and analysis. \n",
    "\n",
    "I used the star schema with Spark because this database is relatively simple and easy to build. With star schema, it is easy to be understand, denormalized and do fast aggregations.\n",
    "The business questions can be, for example, is there any immigration age distribtuion? or do immigrates prefer warmer places? is there any gender trend for immigration? etc. \n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "The data should be updated at least once a month because 1) i94 and temp datasets are both recorded in monthly basis; 2) the data size will be large if updating less frequent than a month; 3) business demands. \n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "     * The data was increased by 100x\n",
    "     \n",
    "1) Discuss with the business analyst on how they would want to use the data and then decide if I need to adjust the star scheme structure. 2) Move the database to AWS and increase EMR cluster size. Apache Spark is linearly scalable so I can add the number of clusters to increase the performance. With AWS EMR I can adjust the size and number of clusters to fit the database. \n",
    "\n",
    "     * The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "     \n",
    "1) Set up a DAG to update the database every hour to get the database ready for the dashboard. \n",
    "2) Create data quality operators to trigger sending emails if the DAG fails to run.\n",
    "3) Combine Airflow + Spark + Apache Livy in the EMR cluster so that Spark commands can be passed through an API interface. \n",
    "\n",
    "     * The database needed to be accessed by 100+ people\n",
    "     \n",
    "1) Use Redshift to wuto-scaling capabilities of the database.\n",
    "2) If the useers do not need to perform insert and update and they only need to access some queries, the data can be periodically copied to a NoSQL server such as Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
